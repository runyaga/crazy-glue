# haiku.rag configuration file
# See https://ggozad.github.io/haiku.rag/configuration/ for details

environment: production
storage:
  data_dir: db
  auto_vacuum: true
  vacuum_retention_seconds: 86400
monitor:
  directories: []
  ignore_patterns: []
  include_patterns: []
  delete_orphans: false
lancedb:
  uri: ''
  api_key: ''
  region: ''
embeddings:
  model:
    provider: ollama
    name: qwen3-embedding:4b
    vector_dim: 2560
    base_url: null
reranking:
  model: null
qa:
  model:
    provider: ollama
    name: gpt-oss
    base_url: null
    enable_thinking: false
    temperature: null
    max_tokens: null
  max_sub_questions: 3
  max_iterations: 2
  max_concurrency: 1
research:
  model:
    provider: ollama
    name: gpt-oss
    base_url: null
    enable_thinking: false
    temperature: null
    max_tokens: null
  max_iterations: 3
  confidence_threshold: 0.8
  max_concurrency: 1
processing:
  chunk_size: 256
  converter: docling-local
  chunker: docling-local
  chunker_type: hybrid
  chunking_tokenizer: Qwen/Qwen3-Embedding-0.6B
  chunking_merge_peers: true
  chunking_use_markdown_tables: false
  conversion_options:
    do_ocr: true
    force_ocr: false
    ocr_lang: []
    do_table_structure: true
    table_mode: accurate
    table_cell_matching: true
    images_scale: 2.0
    generate_picture_images: false
search:
  limit: 5
  context_radius: 0
  max_context_items: 10
  max_context_chars: 10000
  vector_index_metric: cosine
  vector_refine_factor: 30
providers:
  ollama:
    base_url: http://workshop:11434
  docling_serve:
    base_url: http://localhost:5001
    api_key: ''
    timeout: 300
agui:
  host: 0.0.0.0
  port: 8000
  cors_origins:
  - '*'
  cors_credentials: true
  cors_methods:
  - GET
  - POST
  - OPTIONS
  cors_headers:
  - '*'
prompts:
  domain_preamble: ''
  qa: null
  synthesis: null
